{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from MLscripts.proj1_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb, input_data, ids = load_csv_data('data/train.csv', sub_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data[input_data==-999] = np.NaN\n",
    "mean = np.nanmean(input_data, axis=0)\n",
    "inds = np.where(np.isnan(input_data))\n",
    "input_data[inds] = np.take(mean, inds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(input_data, axis=0)\n",
    "std = np.std(input_data, axis=0)\n",
    "\n",
    "input_data = (input_data-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 30)\n",
      "(1000, 30)\n",
      "(4000, 1)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = input_data[:4000], input_data[4000:]\n",
    "y_train, y_test = yb[:4000], yb[4000:]\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- fold 1/4 -----------------\n",
      "Epoch 0: Train loss: [ 127.35059569]. Train accuracy 74.35%. Test accuracy 72.24%\n",
      "Epoch 1: Train loss: [ 104.35890671]. Train accuracy 81.65%. Test accuracy 78.72%\n",
      "Epoch 2: Train loss: [ 95.11062005]. Train accuracy 83.68%. Test accuracy 80.56%\n",
      "Epoch 3: Train loss: [ 89.81757273]. Train accuracy 84.72%. Test accuracy 81.20%\n",
      "Epoch 4: Train loss: [ 85.56041833]. Train accuracy 85.52%. Test accuracy 80.88%\n",
      "Epoch 5: Train loss: [ 82.2129387]. Train accuracy 86.32%. Test accuracy 80.56%\n",
      "Epoch 6: Train loss: [ 79.0285473]. Train accuracy 86.67%. Test accuracy 80.48%\n",
      "Epoch 7: Train loss: [ 75.96181478]. Train accuracy 86.96%. Test accuracy 80.64%\n",
      "Epoch 8: Train loss: [ 73.13947214]. Train accuracy 87.89%. Test accuracy 80.08%\n",
      "Epoch 9: Train loss: [ 70.00499906]. Train accuracy 87.68%. Test accuracy 80.56%\n",
      "Epoch 10: Train loss: [ 68.75653131]. Train accuracy 88.11%. Test accuracy 79.92%\n",
      "Epoch 11: Train loss: [ 67.12231029]. Train accuracy 88.61%. Test accuracy 80.72%\n",
      "Epoch 12: Train loss: [ 63.60194]. Train accuracy 88.61%. Test accuracy 80.32%\n",
      "Epoch 13: Train loss: [ 61.35654875]. Train accuracy 89.15%. Test accuracy 81.04%\n",
      "Epoch 14: Train loss: [ 61.65208603]. Train accuracy 89.01%. Test accuracy 80.80%\n",
      "Epoch 15: Train loss: [ 57.76025611]. Train accuracy 89.97%. Test accuracy 79.92%\n",
      "Epoch 16: Train loss: [ 57.21248188]. Train accuracy 88.72%. Test accuracy 80.72%\n",
      "Epoch 17: Train loss: [ 57.23011815]. Train accuracy 90.43%. Test accuracy 79.68%\n",
      "Epoch 18: Train loss: [ 53.89369438]. Train accuracy 89.07%. Test accuracy 79.20%\n",
      "Epoch 19: Train loss: [ 54.62370074]. Train accuracy 90.13%. Test accuracy 79.76%\n",
      "Epoch 20: Train loss: [ 51.08256407]. Train accuracy 91.33%. Test accuracy 80.56%\n",
      "Epoch 21: Train loss: [ 50.55405491]. Train accuracy 91.12%. Test accuracy 80.24%\n",
      "Epoch 22: Train loss: [ 48.2068565]. Train accuracy 92.05%. Test accuracy 80.24%\n",
      "Epoch 23: Train loss: [ 46.96559366]. Train accuracy 91.04%. Test accuracy 80.08%\n",
      "Epoch 24: Train loss: [ 44.92344308]. Train accuracy 91.76%. Test accuracy 79.36%\n",
      "Epoch 25: Train loss: [ 48.43898038]. Train accuracy 92.48%. Test accuracy 79.12%\n",
      "Epoch 26: Train loss: [ 48.87562083]. Train accuracy 91.89%. Test accuracy 79.92%\n",
      "Epoch 27: Train loss: [ 42.50931694]. Train accuracy 92.93%. Test accuracy 79.28%\n",
      "Epoch 28: Train loss: [ 40.83184605]. Train accuracy 91.41%. Test accuracy 78.80%\n",
      "Epoch 29: Train loss: [ 45.26126017]. Train accuracy 93.12%. Test accuracy 79.52%\n",
      "Epoch 30: Train loss: [ 40.90262207]. Train accuracy 93.57%. Test accuracy 79.60%\n",
      "Epoch 31: Train loss: [ 40.3223766]. Train accuracy 92.59%. Test accuracy 79.68%\n",
      "Epoch 32: Train loss: [ 39.64475361]. Train accuracy 92.48%. Test accuracy 78.16%\n",
      "Epoch 33: Train loss: [ 42.85629781]. Train accuracy 92.29%. Test accuracy 79.28%\n",
      "Epoch 34: Train loss: [ 37.7456176]. Train accuracy 93.68%. Test accuracy 79.60%\n",
      "Epoch 35: Train loss: [ 36.11680464]. Train accuracy 94.21%. Test accuracy 80.40%\n",
      "Epoch 36: Train loss: [ 35.56004595]. Train accuracy 85.63%. Test accuracy 74.80%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6e38a0bc6bc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#model.fit(X_train_T, y_train_T, X_test_T, y_test_T, batch_size=20, epochs=300, log_error=False, verbose=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/EPFL/machine-learning/projects/ML_project1/hotgrad/sequential.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(self, X, y, batch_size, n_splits, epochs, verbose)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EPFL/machine-learning/projects/ML_project1/hotgrad/sequential.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_test, y_test, batch_size, epochs, verbose, log_error)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0msum_loss_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EPFL/machine-learning/projects/ML_project1/hotgrad/sequential.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EPFL/machine-learning/projects/ML_project1/hotgrad/functions/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EPFL/machine-learning/projects/ML_project1/hotgrad/variable.py\u001b[0m in \u001b[0;36m__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \"\"\" Multiplies this Variable by another Variable, i.e. 'other' can only \n\u001b[1;32m     72\u001b[0m         be of type Variable and its shape has to allow for matric multiplication.\"\"\"\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mMatMul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EPFL/machine-learning/projects/ML_project1/hotgrad/functions/operators.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, l_input, r_input)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mr_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhotgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hotgrad.sequential import Sequential\n",
    "\n",
    "from hotgrad.variable import Variable\n",
    "from hotgrad.sequential import Sequential\n",
    "from hotgrad.functions.layers import Linear\n",
    "from hotgrad.functions.activations import ReLU, Tanh\n",
    "from hotgrad.functions.losses import MSE\n",
    "from hotgrad.optimizers import SGD\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "input_data_T = Variable(input_data)\n",
    "yb = yb.reshape(-1,1)\n",
    "yb_T = Variable(yb)\n",
    "\n",
    "X_train_T = Variable(X_train)\n",
    "X_test_T = Variable(X_test)\n",
    "y_train_T = Variable(y_train)\n",
    "y_test_T = Variable(y_test)\n",
    "\n",
    "\n",
    "# model: two input units, two output units, three hidden layers of 25 units\n",
    "model = Sequential([Linear(100), ReLU(), Linear(250), ReLU(), Linear(50), ReLU(), Linear(1), Tanh()], MSE(), SGD(lr=0.1))\n",
    "#model.fit(X_train_T, y_train_T, X_test_T, y_test_T, batch_size=20, epochs=300, log_error=False, verbose=True)\n",
    "model.cross_validate(input_data_T, yb_T, batch_size=20, epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing datasets:\n",
      "\n",
      "processing dataset with samples: 99913 and features: 30\n",
      "replaced 26123 elements with mean (120.667653856) in feature 0\n",
      "decided to delete feature 4\n",
      "decided to delete feature 5\n",
      "decided to delete feature 6\n",
      "decided to delete feature 12\n",
      "decided to delete feature 22\n",
      "decided to delete feature 23\n",
      "decided to delete feature 24\n",
      "decided to delete feature 25\n",
      "decided to delete feature 26\n",
      "decided to delete feature 27\n",
      "decided to delete feature 28\n",
      "processing dataset with samples: 77544 and features: 30\n",
      "replaced 7562 elements with mean (122.182109342) in feature 0\n",
      "decided to delete feature 4\n",
      "decided to delete feature 5\n",
      "decided to delete feature 6\n",
      "decided to delete feature 12\n",
      "decided to delete feature 22\n",
      "decided to delete feature 26\n",
      "decided to delete feature 27\n",
      "decided to delete feature 28\n",
      "processing dataset with samples: 50379 and features: 30\n",
      "replaced 2952 elements with mean (122.653135682) in feature 0\n",
      "decided to delete feature 22\n",
      "processing dataset with samples: 22164 and features: 30\n",
      "replaced 1477 elements with mean (123.189989849) in feature 0\n",
      "decided to delete feature 22\n",
      "datasets processed:\n",
      "\n",
      "\n",
      "Had datasets: (99913, 30), (77544, 30), (50379, 30), (22164, 30)\n",
      "Got datasets: (99913, 19), (77544, 22), (50379, 29), (22164, 29)\n"
     ]
    }
   ],
   "source": [
    "# Divide the dataset\n",
    "from MLscripts.proj1_helpers import *\n",
    "yb, input_data, ids = load_csv_data('data/train.csv', sub_sample=False)\n",
    "\n",
    "# yb is an array of y-values\n",
    "# input_data is array of samples. Each sample is array of 30 features\n",
    "y = yb\n",
    "tx = input_data\n",
    "\n",
    "dataset0 = tx[tx[:, 22] == 0, :]\n",
    "dataset1 = tx[tx[:, 22] == 1, :]\n",
    "dataset2 = tx[tx[:, 22] == 2, :]\n",
    "dataset3 = tx[tx[:, 22] == 3, :]\n",
    "\n",
    "y0 = y[tx[:, 22] == 0]\n",
    "y1 = y[tx[:, 22] == 1]\n",
    "y2 = y[tx[:, 22] == 2]\n",
    "y3 = y[tx[:, 22] == 3]\n",
    "\n",
    "def process_dataset(dataset):\n",
    "    features_to_delete = []\n",
    "    samples_n  = dataset.shape[0]\n",
    "    features_n = dataset.shape[1]\n",
    "    print(\"processing dataset with samples: \" + str(samples_n) + \" and features: \" + str(features_n))\n",
    "    for feature in range(features_n):\n",
    "        full_col = dataset[:, feature]\n",
    "        nans_col = full_col[full_col==-999]\n",
    "        if len(nans_col) == samples_n or feature == 22: # we also have to delete feature 22\n",
    "            print(\"decided to delete feature \" + str(feature))\n",
    "            features_to_delete.append(feature)\n",
    "        elif len(nans_col) != 0:\n",
    "            # let's replace nans with mean\n",
    "            mean = np.mean(full_col[full_col!=-999])\n",
    "            cnt = 0\n",
    "            for i in range(len(full_col)):\n",
    "                if full_col[i] == -999:\n",
    "                    cnt += 1\n",
    "                    full_col[i] = mean\n",
    "            print(\"replaced \" + str(cnt) + \" elements with mean (\" + str(mean) + \") in feature \" + str(feature))\n",
    "    \n",
    "\n",
    "    for i in range(len(features_to_delete) - 1, -1, -1):\n",
    "        dataset = np.delete(dataset, features_to_delete[i], 1)\n",
    "    return dataset\n",
    "\n",
    "print(\"processing datasets:\\n\")\n",
    "pds0 = process_dataset(dataset0)\n",
    "pds1 = process_dataset(dataset1)\n",
    "pds2 = process_dataset(dataset2)\n",
    "pds3 = process_dataset(dataset3)\n",
    "print(\"datasets processed:\\n\\n\")\n",
    "\n",
    "print(\"Had datasets: \" + str(dataset0.shape) + \", \" + str(dataset1.shape) + \", \" + str(dataset2.shape) + \", \" + str(dataset3.shape))\n",
    "print(\"Got datasets: \" + str(pds0.shape) + \", \" + str(pds1.shape) + \", \" + str(pds2.shape) + \", \" + str(pds3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77544, 22)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pds1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77544,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hotgrad.sequential import Sequential\n",
    "\n",
    "from hotgrad.variable import Variable\n",
    "from hotgrad.sequential import Sequential\n",
    "from hotgrad.functions.layers import Linear\n",
    "from hotgrad.functions.activations import ReLU, Tanh\n",
    "from hotgrad.functions.losses import MSE\n",
    "from hotgrad.optimizers import SGD\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "pds0_V = Variable(pds0)\n",
    "pds1_V = Variable(pds1)\n",
    "pds2_V = Variable(pds2)\n",
    "pds3_V = Variable(pds3)\n",
    "\n",
    "y0_V = Variable(y0.reshape(-1,1))\n",
    "y1_V = Variable(y1.reshape(-1,1))\n",
    "y2_V = Variable(y2.reshape(-1,1))\n",
    "y3_V = Variable(y3.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99913, 19)\n",
      "(99913, 1)\n"
     ]
    }
   ],
   "source": [
    "print(pds0_V.shape)\n",
    "print(y0_V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- fold 1/4 -----------------\n",
      "Epoch 0: Train loss: [ 2547.79034611]. Train accuracy 81.96%. Test accuracy 81.76%\n",
      "Epoch 1: Train loss: [ 1953.13317433]. Train accuracy 82.18%. Test accuracy 82.09%\n",
      "Epoch 2: Train loss: [ 1929.89581845]. Train accuracy 82.22%. Test accuracy 82.16%\n",
      "Epoch 3: Train loss: [ 1914.17843553]. Train accuracy 82.35%. Test accuracy 82.19%\n",
      "Epoch 4: Train loss: [ 1876.82991628]. Train accuracy 82.67%. Test accuracy 82.31%\n",
      "Epoch 5: Train loss: [ 1851.55265016]. Train accuracy 82.66%. Test accuracy 82.34%\n",
      "Epoch 6: Train loss: [ 1842.17223608]. Train accuracy 82.67%. Test accuracy 82.38%\n",
      "Epoch 7: Train loss: [ 1835.39866782]. Train accuracy 82.78%. Test accuracy 82.52%\n",
      "Epoch 8: Train loss: [ 1830.01507979]. Train accuracy 82.74%. Test accuracy 82.52%\n",
      "Epoch 9: Train loss: [ 1824.80352132]. Train accuracy 82.81%. Test accuracy 82.59%\n",
      "Epoch 10: Train loss: [ 1821.06234862]. Train accuracy 82.81%. Test accuracy 82.57%\n",
      "Epoch 11: Train loss: [ 1816.78258255]. Train accuracy 82.83%. Test accuracy 82.61%\n",
      "Epoch 12: Train loss: [ 1814.04771148]. Train accuracy 82.88%. Test accuracy 82.66%\n",
      "Epoch 13: Train loss: [ 1811.17054565]. Train accuracy 82.92%. Test accuracy 82.67%\n",
      "Epoch 14: Train loss: [ 1808.32669199]. Train accuracy 82.91%. Test accuracy 82.65%\n",
      "Epoch 15: Train loss: [ 1805.47843136]. Train accuracy 82.94%. Test accuracy 82.65%\n",
      "Epoch 16: Train loss: [ 1802.56276301]. Train accuracy 82.87%. Test accuracy 82.64%\n",
      "Epoch 17: Train loss: [ 1800.23836218]. Train accuracy 82.89%. Test accuracy 82.62%\n",
      "Epoch 18: Train loss: [ 1797.58762265]. Train accuracy 82.84%. Test accuracy 82.57%\n",
      "Epoch 19: Train loss: [ 1795.35924845]. Train accuracy 82.89%. Test accuracy 82.68%\n",
      "Epoch 20: Train loss: [ 1793.13851217]. Train accuracy 83.00%. Test accuracy 82.70%\n",
      "Epoch 21: Train loss: [ 1790.97762963]. Train accuracy 82.85%. Test accuracy 82.63%\n",
      "Epoch 22: Train loss: [ 1788.6155619]. Train accuracy 82.95%. Test accuracy 82.66%\n",
      "Epoch 23: Train loss: [ 1785.53969638]. Train accuracy 82.95%. Test accuracy 82.68%\n",
      "Epoch 24: Train loss: [ 1784.35581852]. Train accuracy 82.96%. Test accuracy 82.67%\n",
      "Epoch 25: Train loss: [ 1781.09780173]. Train accuracy 82.84%. Test accuracy 82.56%\n",
      "Epoch 26: Train loss: [ 1778.41083536]. Train accuracy 82.97%. Test accuracy 82.78%\n",
      "Epoch 27: Train loss: [ 1777.19637124]. Train accuracy 83.14%. Test accuracy 82.82%\n",
      "Epoch 28: Train loss: [ 1774.40674476]. Train accuracy 82.90%. Test accuracy 82.54%\n",
      "Epoch 29: Train loss: [ 1771.65855946]. Train accuracy 82.99%. Test accuracy 82.78%\n",
      "Epoch 30: Train loss: [ 1769.47057277]. Train accuracy 83.10%. Test accuracy 82.84%\n",
      "Epoch 31: Train loss: [ 1766.31266355]. Train accuracy 82.92%. Test accuracy 82.60%\n",
      "Epoch 32: Train loss: [ 1764.9620619]. Train accuracy 83.00%. Test accuracy 82.65%\n",
      "Epoch 33: Train loss: [ 1761.32694133]. Train accuracy 82.97%. Test accuracy 82.68%\n",
      "Epoch 34: Train loss: [ 1759.2922659]. Train accuracy 83.17%. Test accuracy 82.93%\n",
      "Epoch 35: Train loss: [ 1756.1945591]. Train accuracy 83.26%. Test accuracy 82.90%\n",
      "Epoch 36: Train loss: [ 1753.24274129]. Train accuracy 83.23%. Test accuracy 82.93%\n",
      "Epoch 37: Train loss: [ 1751.00995867]. Train accuracy 83.29%. Test accuracy 83.07%\n",
      "Epoch 38: Train loss: [ 1748.30414563]. Train accuracy 83.44%. Test accuracy 83.19%\n",
      "Epoch 39: Train loss: [ 1745.52472123]. Train accuracy 83.31%. Test accuracy 83.09%\n",
      "Epoch 40: Train loss: [ 1742.60141202]. Train accuracy 83.39%. Test accuracy 83.12%\n",
      "Epoch 41: Train loss: [ 1739.34868225]. Train accuracy 83.12%. Test accuracy 82.89%\n",
      "Epoch 42: Train loss: [ 1737.64527332]. Train accuracy 83.65%. Test accuracy 83.28%\n",
      "Epoch 43: Train loss: [ 1735.0719063]. Train accuracy 83.66%. Test accuracy 83.33%\n",
      "Epoch 44: Train loss: [ 1732.29911497]. Train accuracy 83.45%. Test accuracy 83.21%\n",
      "Epoch 45: Train loss: [ 1730.13407913]. Train accuracy 83.38%. Test accuracy 83.07%\n",
      "Epoch 46: Train loss: [ 1727.99482144]. Train accuracy 83.73%. Test accuracy 83.39%\n",
      "Epoch 47: Train loss: [ 1725.49186063]. Train accuracy 83.92%. Test accuracy 83.59%\n",
      "Epoch 48: Train loss: [ 1722.39400124]. Train accuracy 83.80%. Test accuracy 83.35%\n",
      "Epoch 49: Train loss: [ 1719.46816252]. Train accuracy 83.79%. Test accuracy 83.45%\n",
      "Epoch 50: Train loss: [ 1714.68339726]. Train accuracy 83.91%. Test accuracy 83.56%\n",
      "Epoch 51: Train loss: [ 1713.26100285]. Train accuracy 83.92%. Test accuracy 83.63%\n",
      "Epoch 52: Train loss: [ 1708.28513058]. Train accuracy 83.83%. Test accuracy 83.42%\n",
      "Epoch 53: Train loss: [ 1706.546125]. Train accuracy 83.89%. Test accuracy 83.44%\n"
     ]
    }
   ],
   "source": [
    "model0 = Sequential([Linear(100), ReLU(), Linear(250), ReLU(), Linear(50), ReLU(), Linear(1), Tanh()], MSE(), SGD(lr=0.001))\n",
    "model0.cross_validate(pds0_V, y0_V, batch_size=20, epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
